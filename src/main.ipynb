{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import vaex\n",
    "import numpy as np\n",
    "from vaex.ml.sklearn import Predictor\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection as skl_ms\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "main_dir = os.path.normpath(os.getcwd()+os.sep+os.pardir)\n",
    "sys.path.append(main_dir)  # Add the main directory to sys.path\n",
    "# from src.functions import data_prep as fu  # in order to import functions.py\n",
    "# from src.functions import ml_prep as mp  # in order to import functions.py\n",
    "\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "# os.environ['MAX_BATCH_SIZE'] = '32'\n",
    "# import autokeras as ak\n",
    "\n",
    "date_time_fmt = \"%Y/%m/%d %H:%M:%S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset prep\n",
    "df_pd = pd.DataFrame(np.random.randint(2, size=(10**6, 21), dtype=np.uint8))  # vaex data\n",
    "# df_pd = pd.read_csv(\"data/raw/creditcard.csv\").drop(columns=[\"Time\"]).pipe(fu.reduce_mem)  # real data for AK\n",
    "gc.collect()\n",
    "\n",
    "df_pd.columns = [\"v_\"+str(vname) for vname in list(df_pd.columns)]\n",
    "target_vname = \"Class\"\n",
    "df_pd.rename(columns={df_pd.columns[-1]: target_vname}, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# vaex\n",
    "features = df_pd.columns.drop([target_vname]).tolist()\n",
    "df_vaex = vaex.from_pandas(df_pd, copy_index=False)\n",
    "df_vaex_train, df_vaex_test = df_vaex.ml.train_test_split(test_size=0.3, verbose=False)\n",
    "\n",
    "# pandas\n",
    "df_pd.rename(columns={df_pd.columns[-1]: target_vname}, inplace=True, errors=\"ignore\")\n",
    "df_pd_train, df_pd_test = skl_ms.train_test_split(df_pd, test_size=0.3, random_state=123)\n",
    "X_train, y_train = df_pd_train[features], df_pd_train[target_vname]\n",
    "X_test, y_test = df_pd_test[features], df_pd_test[target_vname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGB start\n",
    "# start_time = pd.to_datetime(\"now\")\n",
    "# print(\"Start time:\", start_time.strftime(date_time_fmt))\n",
    "#\n",
    "#\n",
    "# # ML data prep\n",
    "# X_train_xgb, X_test_xgb = mp.dmatricise(X_train, y_train), mp.dmatricise(X_test, y_test)\n",
    "#\n",
    "# params = {\n",
    "#     \"tree_method\": \"hist\",\n",
    "#     \"objective\": \"binary:logistic\",\n",
    "#     \"eval_metric\": \"logloss\"\n",
    "# }\n",
    "# xgb_clf = xgb.XGBClassifier()\n",
    "# xgb_param = xgb_clf.get_xgb_params()\n",
    "# cvresult = xgb.cv(params, X_train_xgb, num_boost_round=100, nfold=10, stratified=True,\n",
    "#        verbose_eval=False, early_stopping_rounds=5)\n",
    "#\n",
    "# xgb_evals_result = dict()\n",
    "# xgb_clf = xgb.train(params, X_train_xgb, evals=[(X_train_xgb, \"train\"), (X_test_xgb, \"test\")],\n",
    "#                     num_boost_round=cvresult.shape[0], verbose_eval=False, early_stopping_rounds=5,\n",
    "#                     evals_result=xgb_evals_result)\n",
    "# print(\"XGBoost logloss on test set:\", xgb_clf.best_score)\n",
    "##  XGBoost logloss on test set: 'logloss': 0.002031\n",
    "\n",
    "## del xgb_clf, X_train_xgb, X_test_xgb\n",
    "## gc.collect()\n",
    "\n",
    "# finish_time = pd.to_datetime(\"now\")\n",
    "# print(\"Finish time:\", finish_time.strftime(date_time_fmt), \"or\", (finish_time-start_time).seconds/60, \"minutes.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Autokeras start\n",
    "# date_time_fmt = \"%Y/%m/%d %H:%M:%S\"\n",
    "# start_time = pd.to_datetime(\"now\")\n",
    "# print(\"Start time:\", start_time.strftime(date_time_fmt))\n",
    "#\n",
    "# ak_clf = ak.StructuredDataClassifier(max_trials=5, loss='binary_crossentropy', objective=\"val_loss\", seed=123)\n",
    "# ak_clf.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "# print(\"AutoKeras logloss on test set:\", ak_clf.evaluate(X_test, y_test))\n",
    "# # AutoKeras logloss on test set: 0.0038057671467236565\n",
    "#\n",
    "# finish_time = pd.to_datetime(\"now\")\n",
    "# print(\"Finish time:\", finish_time.strftime(date_time_fmt), \"or\", (finish_time-start_time).seconds/60, \"minutes.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2020/04/30 18:06:19\n",
      "Balanced accuracy: -0.12%\n",
      "Finish time: 2020/04/30 18:07:38 or 1.32 minutes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Vaex start\n",
    "start_time = pd.to_datetime(\"now\")\n",
    "print(\"Start time:\", start_time.strftime(date_time_fmt))\n",
    "\n",
    "# ML\n",
    "# print(type(ak_clf))\n",
    "xgb_clf_vaex = xgb.XGBClassifier()\n",
    "vaex_model = Predictor(model=xgb_clf_vaex, features=features, target=target_vname, prediction_name='pred')\n",
    "vaex_model.fit(df=df_vaex_train)\n",
    "vaex_preds = vaex_model.transform(df_vaex_test)\n",
    "vaex_bacuracy = balanced_accuracy_score(y_test, vaex_preds.to_pandas_df()[target_vname], adjusted=True)\n",
    "print(\"Balanced accuracy: %.2f%%\" % (vaex_bacuracy * 100.0))\n",
    "\n",
    "finish_time = pd.to_datetime(\"now\")\n",
    "print(\"Finish time:\", finish_time.strftime(date_time_fmt), \"or\", round((finish_time-start_time).seconds/60, 2), \"minutes.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2020/04/30 18:07:38\n",
      "Balanced accuracy: 0.04%\n",
      "Finish time: 2020/04/30 18:09:02 or 1.4 minutes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## XGB start\n",
    "start_time = pd.to_datetime(\"now\")\n",
    "print(\"Start time:\", start_time.strftime(date_time_fmt))\n",
    "\n",
    "# ML\n",
    "xgb_clf_pd = xgb.XGBClassifier()\n",
    "xgb_model = xgb_clf_pd.fit(X_train, y_train)\n",
    "pd_preds = xgb_model.predict(X_test)\n",
    "# pd_preds = [round(value) for value in pd_preds]\n",
    "pd_bacuracy = balanced_accuracy_score(y_test, pd_preds, adjusted=True)\n",
    "print(\"Balanced accuracy: %.2f%%\" % (pd_bacuracy * 100.0))\n",
    "\n",
    "finish_time = pd.to_datetime(\"now\")\n",
    "print(\"Finish time:\", finish_time.strftime(date_time_fmt), \"or\", round((finish_time-start_time).seconds/60, 2), \"minutes.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
